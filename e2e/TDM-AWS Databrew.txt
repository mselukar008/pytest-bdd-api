1.Create a dataset using  csv file from s3 bucket
2.The db contains sensitive info as email,credit card number,btc addresss and ip-address
3.Sample the data to show only 700 records
4.Apply Masking rules on sensitive columns.
	-Redact credit card number and btc address using #
	-Shuffle ip_address
	-shuffle email
5.Sort gender column in Ascending
6.Store the output in s3 bucket

========================================

Use Cases for TDM

1. Data Injection using csv,excel,json,jsonl,orc,parquet etc files through Amazon s3 bucket.
2. Cloud to Cloud Migration though AWS Glue Data Catalog - You can use the Data Catalog to define references to data that's stored in the AWS Cloud. With the Data Catalog, you can build connections to individual tables in the following services:
	Data Catalog Amazon S3
	Data Catalog Amazon Redshift
	Data Catalog Amazon RDS
	AWS Glue
3.Data connected using JDBC drivers - 
	Microsoft SQL Server
	MySQL
	Oracle
	PostgreSQL
	Amazon Redshift
	Snowflake Connector for Spark

4.Amazon Appflow - Using Amazon AppFlow, you can transfer data into Amazon S3 from third-party Software-as-a-Service (SaaS) applications such as Salesforce, Zendesk, Slack, and ServiceNow. You can then use the data to create a DataBrew dataset.

5.AWS Data Exchange - third-party data sources are available in AWS Data Exchange. By subscribing to these data sources, you get the most up-to-date version of the data.
